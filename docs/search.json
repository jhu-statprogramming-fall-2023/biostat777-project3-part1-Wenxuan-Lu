[{"path":"/articles/my_vignette.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Example Analysis","text":"National Football League (NFL) just sport. ’s part American culture attracts attention million across nation. analysis, going explore factors can influence weekly attendance use lasso regression predict weekly attendance. aiming questions home field advantage real? home field advantage real, number attendants increase home game? Can predict weekly attendance basic information teams? addition , explore question 3 build model access data restricted, show usage data integration method package htlgmm.","code":""},{"path":"/articles/my_vignette.html","id":"dataset","dir":"Articles","previous_headings":"","what":"Dataset","title":"Example Analysis","text":"data set obtained package tidytuesday week 2020-02-04. originated Pro Football Reference team standings. data set contains weekly attendance information games 2000 2019. also provides information game rating teams. Please refer data dictionary details.","code":"# load libraries library(htlgmm) library(tidytuesdayR) library(tidyr) library(dplyr) library(purrr) library(ggplot2) library(glmnet) # create a data folder if needed if (!file.exists(\"../data\")) {   dir.create(\"../data\") }  # download data from tidytuesday and save it if needed if (!file.exists(\"../data/attendance.rds\")) {     attendance <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-04/attendance.csv')     standings <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-04/standings.csv')     games <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-02-04/games.csv')     saveRDS(attendance, \"../data/attendance.rds\")     saveRDS(standings, \"../data/standings.rds\")     saveRDS(games, \"../data/games.rds\") } # load the data set attendance = as_tibble(readRDS(\"../data/attendance.rds\")) standings = as_tibble(readRDS(\"../data/standings.rds\")) games = as_tibble(readRDS(\"../data/games.rds\"))"},{"path":"/articles/my_vignette.html","id":"q1-is-the-home-field-advantage-real","dir":"Articles","previous_headings":"","what":"Q1: Is the home field advantage real?","title":"Example Analysis","text":"common saying home team advantage away team. advantage real? Figure 1 shows percentage games won home teams. row corresponds distribution weekly percentage games won home teams given year. consistent trend home teams won games away games. Figure 2 shows percentage points gained home teams. Though points depend factors competence team, home teams typically earn points, confirms home field advantage. Figure 3 4 show home field advantage even larger Wild Card round, Divisional Round, Conference Championship, Super Bowl. Figure 1: percentage wins made home teams Figure 2: percentage points made home teams Figure 3: percentage wins made home teams year’s Wild Card round, Divisional Round, Conference Championship, Super Bowls Figure 4: percentage points made home teams year’s Wild Card round, Divisional Round, Conference Championship, Super Bowls","code":"games[\"is_home_win\"] = map2_int(.x=games$winner,                                  .y=games$home_team,                                  .f = function(x, y) as.numeric(x==y)) games[\"home_pts_percent\"] = pmap_dbl(.l=games[c(\"is_home_win\", \"pts_win\", \"pts_loss\")],                                       .f=function(is_home_win, pts_win, pts_loss) {                                          ifelse(is_home_win, pts_win, pts_loss)/(pts_win + pts_loss)                                      }) to_plot = games %>%      select(year, week, is_home_win, home_pts_percent, home_team_name, away_team_name) %>%     mutate(team_name=home_team_name) %>%     inner_join(standings[c(\"year\", \"team_name\", \"playoffs\")],                 by = join_by(year, team_name)) %>%     rename(home_playoffs=playoffs) %>%     mutate(team_name=away_team_name) %>%     inner_join(standings[c(\"year\", \"team_name\", \"playoffs\")],                by = join_by(year, team_name)) %>%     rename(away_playoffs=playoffs) %>%     mutate(time=paste0(year, \"/\", week)) %>%     mutate(playoffs=case_when(         home_playoffs == \"Playoffs\" & away_playoffs == \"Playoffs\" ~ \"Both Playoffs\",         home_playoffs == \"Playoffs\" & away_playoffs == \"No Playoffs\" ~ \"Home Playoffs\",         home_playoffs == \"No Playoffs\" & away_playoffs == \"Playoffs\" ~ \"Away Playoffs\",         .default = \"None Playoffs\"     )) %>%     select(time, year, week, playoffs, is_home_win, home_pts_percent) plot_df = to_plot %>%      filter(!week %in% c(\"WildCard\", \"Division\", \"ConfChamp\", \"SuperBowl\")) %>%     mutate(week = as.numeric(week)) %>%     group_by(time, year, week) %>%     summarize(is_home_win_avg = mean(is_home_win),               home_pts_percent_avg = mean(home_pts_percent),               .groups=\"drop\") %>%     arrange(year, week) %>%     mutate(year = factor(year))  ggplot(data=plot_df, aes(year, is_home_win_avg)) +     geom_boxplot(aes(fill=year), show.legend = FALSE) +     coord_flip() +     labs(title = \"The percentage of wins made by home teams\",           subtitle = \"For each year, the box shows the distribution of the percentage of games won \\nby home teams each week\",          caption = \"Data Source: NFL Stadium Attendance (TidyTuesday 2020-02-04)\",          x = \"year\",          y = \"percentage of home wins\") +      theme_minimal() +     theme(axis.text.y = element_text(angle = 30, hjust = 1, size=6)) plot_df = to_plot %>%      filter(!week %in% c(\"WildCard\", \"Division\", \"ConfChamp\", \"SuperBowl\")) %>%     mutate(year = factor(year))  ggplot(data=plot_df, aes(year, home_pts_percent)) +     geom_boxplot(aes(fill=year), show.legend = FALSE) +     coord_flip() +     labs(title = \"The percentage of points made by home teams\",           subtitle = \"The percentage points made by home teams for each game\",          caption = \"Data Source: NFL Stadium Attendance (TidyTuesday 2020-02-04)\",          x = \"year\",          y = \"percentage of points made by home teams\") +      theme_minimal() +     theme(axis.text.y = element_text(angle = 30, hjust = 1, size=6)) plot_df = to_plot %>%      filter(week %in% c(\"WildCard\", \"Division\", \"ConfChamp\", \"SuperBowl\")) %>%     group_by(year, week) %>%     summarize(is_home_win_avg = mean(is_home_win),               home_pts_percent_avg = mean(home_pts_percent),               .groups=\"drop\")  ggplot(data=plot_df, aes(year, is_home_win_avg)) +     geom_line() + geom_point() +     facet_wrap(~week, scales=\"fixed\") +     labs(title = \"The percentage of wins by home teams\",           subtitle = \"The mean percentage of winning by home teams for each year's \\nWild Card round, Divisional Round, the Conference Championship, and the Super Bowls\",          caption = \"Data Source: NFL Stadium Attendance (TidyTuesday 2020-02-04)\",          x = \"year\",          y = \"percentage of home wins\") +      theme(axis.text.x = element_text(angle = 30, hjust = 1, size=6)) ggplot(data=plot_df, aes(year, home_pts_percent_avg)) +     geom_line() + geom_point() +     facet_wrap(~week, scales=\"fixed\") +     labs(title = \"The percentage of points made by home teams\",           subtitle = \"The mean percentage of points made by home teams for each year's \\nWild Card round, Divisional Round, the Conference Championship, and the Super Bowls\",          caption = \"Data Source: NFL Stadium Attendance (TidyTuesday 2020-02-04)\",          x = \"year\",          y = \"percentage of points made by home teams\") +      theme(axis.text.x = element_text(angle = 30, hjust = 1, size=6))"},{"path":"/articles/my_vignette.html","id":"q2-does-the-number-of-attendants-increase-when-it-is-a-home-game","dir":"Articles","previous_headings":"","what":"Q2: Does the number of attendants increase when it is a home game?","title":"Example Analysis","text":"home team tends supporters locally. Moreover, due home field advantage, people might come witness winning home team. Thus, reasonable suspect number attendants games involving given team tends increase home game. Indeed, Figure 5 supports argument. Nevertheless, can see variation attendance home game away game large, indicating many factors also influence attendance. Thus, building regression model next section, additional variables relate team competence opponent quality included. Figure 5: mean increase attendance home games compared away games team","code":"attendance = filter(attendance, !is.na(attendance$weekly_attendance)) home_games = games %>%      select(year, week,             home_team_name, home_team_city, is_home_win,             away_team_name, away_team_city) %>%     mutate(is_home = 1) %>%     rename(is_win = is_home_win,             team_name = home_team_name, team = home_team_city,            other_team_name = away_team_name, other_team = away_team_city) away_games = games %>%      select(year, week,             away_team_name, away_team_city, is_home_win,             home_team_name, home_team_city) %>%     mutate(is_home = 0, is_home_win = 1 - is_home_win) %>%     rename(is_win = is_home_win,             team_name = away_team_name, team = away_team_city,            other_team_name = home_team_name, other_team = home_team_city) is_win_df = rbind(home_games, away_games) %>%     filter(!week %in% c(\"WildCard\", \"Division\", \"ConfChamp\", \"SuperBowl\")) %>%     mutate(week = as.numeric(week)) %>%      inner_join(attendance[c(\"year\", \"week\", \"team_name\", \"team\", \"weekly_attendance\")],                by = c(\"year\"=\"year\", \"week\"=\"week\", \"other_team_name\"=\"team_name\", \"other_team\"=\"team\")) %>%     inner_join(standings[c(\"year\", \"team\", \"team_name\",                             \"margin_of_victory\", \"strength_of_schedule\", \"playoffs\")],                by = c(\"year\"=\"year\", \"other_team_name\"=\"team_name\", \"other_team\"=\"team\")) %>%     mutate(playoffs = case_when(         playoffs==\"Playoffs\" ~ 1,          playoffs==\"No Playoffs\" ~ 0)) %>%     rename(other_weekly_attendance=weekly_attendance,             other_margin_of_victory=margin_of_victory,            other_strength_of_schedule=strength_of_schedule,            other_playoffs=playoffs) %>%     inner_join(attendance[c(\"year\", \"week\", \"team_name\", \"team\", \"weekly_attendance\")],                by = join_by(year, week, team_name, team)) %>%     inner_join(standings[c(\"year\", \"team\", \"team_name\",                             \"margin_of_victory\", \"strength_of_schedule\", \"playoffs\")],                by = join_by(year, team_name, team)) %>%     mutate(playoffs = case_when(         playoffs==\"Playoffs\" ~ 1,          playoffs==\"No Playoffs\" ~ 0)) plot_df = is_win_df %>%     group_by(year, team_name, is_home) %>%     summarise(mean_weekly_attendance = mean(weekly_attendance), .groups=\"drop\") %>%     pivot_wider(names_from = is_home, values_from = mean_weekly_attendance) %>%     mutate(weekly_attendance_diff = `1` - `0`) %>%     mutate(year = as.factor(year))  ggplot(data=plot_df, aes(x=year, y=weekly_attendance_diff))+     geom_boxplot(aes(fill=year), show.legend = FALSE) +     coord_flip() +     labs(title = \"The difference in mean weekly attendance between home and away games\",           subtitle = \"The mean increase in attendance for home games compared with\\n away games for each team\",          caption = \"Data Source: NFL Stadium Attendance (TidyTuesday 2020-02-04)\",          x = \"year\",          y = \"increase in attendance for home games\") +      theme_minimal() +     theme(axis.text.y = element_text(angle = 30, hjust = 1, size=6))"},{"path":"/articles/my_vignette.html","id":"q3-can-we-predict-the-weekly-attendance","dir":"Articles","previous_headings":"","what":"Q3: Can we predict the weekly attendance?","title":"Example Analysis","text":"exploratory analysis shows whether game home game can partially explain variance weekly attendance. better model weekly attendance, information opponent quality game well team competence evaluated year also included. lasso regression used predict weekly attendance. 80%/20% train/test split performed, test MSE used evaluate model. Sometimes, might access subset data (main study). remaining data may restricted access available summary statistics fitted reduced model (external study). Since external study large sample size, estimated model coefficients tend accurate smaller variance. Rather fitting model main study small sample size, integrating summary statistics external data main study may elevate performance model. illustrate htlgmm can used data integration, training set randomly splitted main study (20%) external study (80%). following three models fitted compared. Model 1: fit full model using lasso regression training data. Model 2: fit full model using lasso regression main study Model 3: fit full model using lasso regression main study using summary statistics reduced model external study Model 1 results lowest test MSE access data. Compared model 2 uses data main study, model 3 performs better borrows additional information external study. shows even model fitted external study full model used main study, can still integrate summary statistics model fitted main study.","code":"data_df = is_win_df %>%     mutate(is_home_win = case_when(         is_win == 1 & is_home == 1 ~ 1,         is_win == 0 & is_home == 0 ~ 1,         .default = 0     )) %>%     mutate(playoff_status = playoffs + other_playoffs) %>%     mutate(margin_of_victory_status = abs(margin_of_victory) + abs(other_margin_of_victory)) %>%     mutate(strength_of_schedule_status = abs(strength_of_schedule) + abs(other_strength_of_schedule)) %>%     select(is_home_win, playoff_status, margin_of_victory_status, strength_of_schedule_status,            margin_of_victory, strength_of_schedule,             other_margin_of_victory, other_strength_of_schedule,             weekly_attendance) set.seed(1) data_df_scaled = as_tibble(scale(data_df)) train_index = sample(1:nrow(data_df_scaled), size=round(nrow(data_df_scaled) * 0.8)) train_df = data_df_scaled[train_index, ] test_df = data_df_scaled[-train_index, ] external_proportion = 0.8 external_index = sample(train_index, size=round(length(train_index)* external_proportion)) train_external_df = data_df_scaled[external_index, ] train_main_df = data_df_scaled[setdiff(train_index, external_index), ]  # transform data into matrices train_X = as.matrix(train_df[, -9]) train_y = as.matrix(train_df[, 9]) train_main_X = as.matrix(train_main_df[, -9]) train_main_y = as.matrix(train_main_df[, 9]) train_external_X = as.matrix(train_external_df[, -9]) train_external_y = as.matrix(train_external_df[, 9]) test_X = as.matrix(test_df[, -9]) set.seed(1)  # Case 1: we have access to all data all_lasso = cv.glmnet(train_X, train_y, alpha = 1) all_pred = predict(all_lasso,                               newx = test_X,                    s = all_lasso$lambda.min) all_mse = mean((all_pred - test_df$weekly_attendance)^2)  # Case 2: we have only a small sample of data internal_only_lasso = cv.glmnet(train_main_X, train_main_y, alpha = 1) internal_only_pred = predict(internal_only_lasso,                               newx = test_X, s = internal_only_lasso$lambda.min) internal_only_mse = mean((internal_only_pred - test_df$weekly_attendance)^2)  # Case 3: an external model is provided external_lm = lm(weekly_attendance~., data=train_external_df[c(\"margin_of_victory\",                                                                \"strength_of_schedule\",                                                              \"weekly_attendance\")]) study_info<-list() study_external = list(     Coeff=external_lm$coefficients[-1],     Covariance=vcov(external_lm)[-1,-1],     Sample_size=nrow(train_external_df)) study_info[[1]] <- study_external Y = train_main_y Z = train_main_X[, c(\"margin_of_victory\",\"strength_of_schedule\")] W = subset(train_main_X,             select = -which(colnames(train_main_X) %in%                                 c(\"margin_of_victory\",\"strength_of_schedule\"))) res_htlgmm.cv<-cv.htlgmm(y=as.numeric(Y),                    Z=Z,                    W=W,                    A=1,                    study_info = study_info,                    family = \"gaussian\",                    penalty_type = \"lasso\",                    use_sparseC = FALSE,                    inference=FALSE,                    nfold=10) res_htlgmm<-htlgmm(y=as.numeric(Y),                    Z=Z,                    W=W,                    A=1,                    study_info = study_info,                    family = \"gaussian\",                    penalty_type = \"lasso\",                    use_sparseC = FALSE,                    inference=FALSE,                    fix_lambda = res_htlgmm.cv$lambda_min) htlgmm_cv_pred = test_X %*% res_htlgmm$beta[c(4, 5, 6, 7, 2, 3, 8, 9)] + res_htlgmm$beta[1] htlgmm_mse = mean((htlgmm_cv_pred - test_df$weekly_attendance)^2)  # display the results cat(sprintf(\"MSE for model 1 (all):       %.4f\\nMSE for model 2 (main only): %.4f\\nMSE for model 3 (htlgmm):    %.4f\", all_mse, internal_only_mse, htlgmm_mse)) #> MSE for model 1 (all):       0.9770 #> MSE for model 2 (main only): 0.9809 #> MSE for model 3 (htlgmm):    0.9786"},{"path":"/articles/my_vignette.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Example Analysis","text":"analysis aims investigate factors affecting weekly attendance NFL games build lasso regression model predict weekly attendance. exploratory analysis shows home field advantage exists, game home city tends higher attendance. city information, well information opponent quality team’s yearly competence ratings, used predict weekly attendance. test MSE scaled data 0.977. Moreover, explored scenario access summary statistics external study large sample size individual level data main study small sample size. data integration method htglmm used integrate summary statistics main study, test MSE decreases, illustrates effectiveness integration method.","code":""},{"path":"/articles/my_vignette.html","id":"functions-used-in-the-analysis","dir":"Articles","previous_headings":"","what":"Functions used in the analysis","title":"Example Analysis","text":"purrr package: map2_int, pmap_dbl dypyr package: select, mutate, rename, inner_join, case_when, group_by, summarize, filter, arrange ggplot2 package: geom_boxplot, geom_line, geom_point, facet_wrap htlgmm package: htlgmm, htlgmm.cv","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Ruzhang Zhao. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Zhao R (2023). htlgmm: Hetergeneous Transfer Learning via Generalized Method Moments. R package version 0.1.0.","code":"@Manual{,   title = {htlgmm: Hetergeneous Transfer Learning via Generalized Method of Moments},   author = {Ruzhang Zhao},   year = {2023},   note = {R package version 0.1.0}, }"},{"path":"/index.html","id":"htlgmm","dir":"","previous_headings":"","what":"Hetergeneous Transfer Learning via Generalized Method of Moments","title":"Hetergeneous Transfer Learning via Generalized Method of Moments","text":"package website build project 3 class 140.777 Statistical Programming Paradigms Workflows.","code":""},{"path":"/index.html","id":"pakcage-information","dir":"","previous_headings":"","what":"Pakcage information","title":"Hetergeneous Transfer Learning via Generalized Method of Moments","text":"Original GitHub Repo: [https://github.com/RuzhangZhao/htlgmm] Deployed website: [https://jhu-statprogramming-fall-2023.github.io/biostat777-project3-part1-Wenxuan-Lu/] Author: Ruzhang Zhao (developed package), Wenxuan Lu (developed website made example analysis) Goal package: Perform hetergeneous transfer learning via generalized method moments Exported functions: htlgmm: fit generalized linear model via penalized generalized method moments htlgmm.cv: perform k-fold cross validation htlgmm","code":""},{"path":"/index.html","id":"website-customization","dir":"","previous_headings":"","what":"Website Customization","title":"Hetergeneous Transfer Learning via Generalized Method of Moments","text":"Use bootswatch spacelab theme. Change font text headings bslib variables. Change syntax highlighting color breeze-light code blocks. Add link original GitHub repository sidebar. Change background color used inline code.","code":""},{"path":"/index.html","id":"example-usage","dir":"","previous_headings":"","what":"Example usage","title":"Hetergeneous Transfer Learning via Generalized Method of Moments","text":"Please see google colab link [https://colab.research.google.com/drive/1TWE3ZT30fY1umL_ILoeC2iwS8oTn66aT?usp=sharing] tutorial. works README file htlgmm function. pZ = 20, pW = 3","code":"# Simulation Example library(htlgmm) pZ=20 # overlapping features pW=3 # unmatched features  coef<-c(rep(0,pZ+pW)) coef[1:3]<-0.5 coef[c(21,22)]<-0.5 which(coef!=0)  n=400 nE=2000 n_joint=n+nE main_index<-1:n  set.seed(202) Z_joint<-matrix(rnorm(n_joint*pZ),n_joint,pZ) colnames(Z_joint)<-paste0(\"Z\",1:pZ) W_joint<-matrix(rnorm(n_joint*pW),n_joint,pW) colnames(W_joint)<-paste0(\"W\",1:pW) Z<-Z_joint[main_index,]  # separate main and external study for Z ZE<-Z_joint[-main_index,]  W<-W_joint[main_index,] # only need main study for W  y_joint<-cbind(Z_joint,W_joint)%*%coef+rnorm(n_joint,0,1) y<-y_joint[main_index] # separate main study y yE<-y_joint[-main_index] # separate external study y  Z<-scale(Z) ZE<-scale(ZE) W<-scale(W)  library(glmnet) res_glmnet<-cv.glmnet(x=cbind(Z,W),y=y) est_coef_glmnet<-coef.glmnet(res_glmnet,s=\"lambda.min\")[-1] # without intercept  reslm<-lm(y~.,data = data.frame(y=yE,ZE)) study_external = list(                 Coeff=reslm$coefficients[-1],                 Covariance=vcov(reslm)[-1,-1],                 Sample_size=nE) study_info<-list() study_info[[1]] <- study_external # The study_info is also a list because we can support multiple external studies.   y<-scale(y,center = TRUE, scale = FALSE) # only do centering for main study y.   res_htlgmm<-cv.htlgmm(y=y,                       Z=Z,                       W=W,                       study_info = study_info,                       family = \"gaussian\",                       penalty_type = \"lasso\",                       use_sparseC = TRUE)  est_coef_htlgmm<-res_htlgmm$beta names(est_coef_htlgmm)<-c(paste0('Z',1:pZ),paste0('W',1:pW))  est_coef_htlgmm<-res_htlgmm$beta ee_htlgmm<-sum((coef-est_coef_htlgmm)^2) ee_htlgmm<-round(ee_htlgmm,4)  ee_lasso<-sum((coef-est_coef_glmnet)^2) ee_lasso<-round(ee_lasso,4) print(paste0(\"Estimation Error: \",\"lasso(\",ee_lasso,\"); htlgmm(\",ee_htlgmm,\")\")) [1] \"Estimation Error: lasso(0.0414); htlgmm(0.0212)\""},{"path":"/reference/cv.htlgmm.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross validation for htlgmm. — cv.htlgmm","title":"Cross validation for htlgmm. — cv.htlgmm","text":"htlgmm fits generalized linear model via penalized generalized method moments, .e. Heterogeneous Transfer Learning via Generalized Method Moments. input requires main study external study. cv.htlgmm k-fold cross validation htlgmm.","code":""},{"path":"/reference/cv.htlgmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross validation for htlgmm. — cv.htlgmm","text":"","code":"cv.htlgmm(   y,   Z,   W = NULL,   study_info = NULL,   A = \"default\",   penalty_type = \"adaptivelasso\",   family = \"gaussian\",   initial_with_type = \"ridge\",   beta_initial = NULL,   hat_thetaA = NULL,   V_thetaA = NULL,   use_offset = TRUE,   V_thetaA_sandwich = TRUE,   remove_penalty_Z = FALSE,   remove_penalty_W = FALSE,   inference = TRUE,   use_cv = TRUE,   type_measure = \"default\",   nfolds = 10,   fix_lambda = NULL,   lambda_list = NULL,   tune_ratio = FALSE,   fix_ratio = NULL,   ratio_list = NULL,   gamma_adaptivelasso = 1/2,   use_sparseC = TRUE,   seed.use = 97 )"},{"path":"/reference/cv.htlgmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross validation for htlgmm. — cv.htlgmm","text":"y variable interest, can continuous binary. Z overlapping features main external studies. W unmatched features main study, default NULL. study_info trained model external study, including estimate coefficients, estimated variance-covariance matrix sample size. 'study_info' format list. first item 'Coeff', second iterm 'Covariance', third item 'Sample_size'. covariates study-specific adjustment. default 'default', 'NULL' 'gaussian' family, '1' 'binomial' family. c('default',NULL,1), must matrix whose dimension sample dimension Z W. continuous variable, suggest scaling features Z, W eliminate intercept term.  '= NULL', intercept term included. binary variable, use intercept term '=1' adjust different binary trait ratios main external studies. intercept term , use '=1'. features working adjustment reduced model, summarized summary statistics(input:study_info). penalty_type penalty type htlgmm, chosen c(\"none\",\"lasso\",\"adaptivelasso\",\"ridge\"). default \"adaptivelasso\". 'penalty_type = 'none' ', use without penalty. (continuous y, use ordinary least square, binary y, use logistic regression without penalty.) family family chosen c(\"gaussian\",\"binomial\"). Linear regression \"gaussian\" logistic regression \"binomial\". initial_with_type Get initial estimation beta using main study data cross validation using penalty regression, chosen c(\"ridge\",\"lasso\",\"glm\"). default \"ridge\". penalty_type = 'glm', continuous y, use ordinary least square, binary y, use logistic regression without penalty.) beta_initial initial estimation beta consistent estimator available. E.g., one may input htlgmm result beta_initial rounds refine final estimation. default NULL, main study used initial estimation according 'initial_with_type'. hat_thetaA NULL, one can provide hat_thetaA input. 'hat_thetaA = NULL', estimate hat_thetaA glm main study. V_thetaA NULL, one can provide V_thetaA input. 'V_thetaA = NULL', estimate V_thetaA glm main study. use_offset Whether use offset regarding external model estimated coefficient. default TRUE. V_thetaA_sandwich Whether apply sandwich formula compute variance-covariance matrix hat_thetaA.default TRUE. remove_penalty_Z penalize Z TRUE. default FALSE. remove_penalty_W penalize W TRUE. default FALSE. inference Whether inference without penalty post-selection inference adaptive lasso penalty. default TRUE. use_cv Whether use cross validation determine best lambda (ratio). type_measure Select c(\"default\", \"mse\", \"deviance\", \"auc\"). Default mse(liner), deviance(logistic). 'auc' another choice binary y. nfolds fold number cross validation. work use_cv = TRUE.default 10. fix_lambda Without cross validation, fix lambda. default NULL. lambda_list Customize input lambda list validation. default NULL generate lambda list according glmnet. tune_ratio Whether use two-lambda stratgey. default TRUE. fix_ratio fixed ratio two-lambda strategy. ratio multiplied Z features. default NULL. NULL, select best ratio via cross validation holdout validation. ratio_list ratio list preset. default NULL ratio list generated. gamma_adaptivelasso gamma adaptive lasso. Select c(1/2,1,2). default 1/2. use_sparseC Whether use approximate version weighting matrix C. approximation, use diagonal inverse C(inv_C) approximate inv_C. default TRUE. main study sample size limited, use_sparseC = TRUE recommended. main study sample size large enough, use_sparseC = FALSE recommended. seed.use seed  97.","code":""},{"path":"/reference/cv.htlgmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross validation for htlgmm. — cv.htlgmm","text":"beta: target coefficient estimation, features go order (,Z,W). lambda_list: lambda list cross validation. ratio_list: ratio list validation (cross validation holdout validation). fix_lambda: fix_lambda null, output fix_lambda. fix_ratio: fix_ratio null, output fix_ratio. lambda_min: selected best lambda cross validation. ratio_min: selected best ratio cross validation. cv_mse: mean square error(mse) family = \"gaussian\", use_cv = TRUE. cv_dev: deviance(dev) family = \"binomial\", use_cv = TRUE. cv_auc: area curve sensitivity specificity family = \"binomial\", use_cv = TRUE. selected_vars: inference post-selection inference, output inference results list. position: index nonzero positions, index comes X = (,Z,W). name: feature name nonzero positions. default name, name Ai, Zi, Wi. coef: coefficients nonzero positions. variance: variances features glm inference, selected features post-selection inference. pval: p values nonzero positions. FDR_adjust_position: FDR adjusted positions passing significant level 0.05 BH adjustment (Benjamini & Hochberg). FDR_adjust_name: feature name based FDR_adjust_position.","code":""},{"path":"/reference/cv.htlgmm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross validation for htlgmm. — cv.htlgmm","text":"Cross validation htlgmm.","code":""},{"path":"/reference/htlgmm.html","id":null,"dir":"Reference","previous_headings":"","what":"htlgmm: — htlgmm","title":"htlgmm: — htlgmm","text":"htlgmm fits generalized linear model via penalized generalized method moments, .e. Heterogeneous Transfer Learning via Generalized Method Moments. input requires main study external study.","code":""},{"path":"/reference/htlgmm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"htlgmm: — htlgmm","text":"","code":"htlgmm(   y,   Z,   W = NULL,   study_info = NULL,   A = \"default\",   penalty_type = \"none\",   family = \"gaussian\",   initial_with_type = \"glm\",   beta_initial = NULL,   hat_thetaA = NULL,   V_thetaA = NULL,   use_offset = TRUE,   V_thetaA_sandwich = TRUE,   remove_penalty_Z = FALSE,   remove_penalty_W = FALSE,   inference = TRUE,   fix_lambda = NULL,   lambda_list = NULL,   fix_ratio = NULL,   gamma_adaptivelasso = 1/2,   use_sparseC = TRUE,   seed.use = 97 )"},{"path":"/reference/htlgmm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"htlgmm: — htlgmm","text":"y variable interest, can continuous binary. Z overlapping features main external studies. W unmatched features main study, default NULL. study_info trained model external study, including estimate coefficients, estimated variance-covariance matrix sample size. 'study_info' format list. first item 'Coeff', second iterm 'Covariance', third item 'Sample_size'. covariates study-specific adjustment. default 'default', 'NULL' 'gaussian' family, '1' 'binomial' family. c('default',NULL,1), must matrix whose dimension sample dimension Z W. continuous variable, suggest scaling features Z, W eliminate intercept term.  '= NULL', intercept term included. binary variable, use intercept term '=1' adjust different binary trait ratios main external studies. intercept term , use '=1'. features working adjustment reduced model, summarized summary statistics(input:study_info). penalty_type penalty type htlgmm, chosen c(\"none\",\"lasso\",\"adaptivelasso\",\"ridge\"). default \"none\". 'penalty_type = 'none' ', use without penalty. (continuous y, use ordinary least square, binary y, use logistic regression without penalty.) family family chosen c(\"gaussian\",\"binomial\"). Linear regression \"gaussian\" logistic regression \"binomial\". initial_with_type Get initial estimation beta using main study data cross validation using (penalty) regression, chosen c(\"ridge\",\"lasso\",\"glm\"). default \"ridge\". penalty_type = 'glm', continuous y, use ordinary least square, binary y, use logistic regression without penalty.) beta_initial initial estimation beta consistent estimator available. E.g., one may input htlgmm result beta_initial rounds refine final estimation. default NULL, main study used initial estimation according 'initial_with_type'. hat_thetaA NULL, one can provide hat_thetaA input. 'hat_thetaA = NULL', estimate hat_thetaA glm main study. V_thetaA NULL, one can provide V_thetaA input. 'V_thetaA = NULL', estimate V_thetaA glm main study. use_offset Whether use offset regarding external model estimated coefficient. default TRUE. V_thetaA_sandwich Whether apply sandwich formula compute variance-covariance matrix hat_thetaA.default TRUE. remove_penalty_Z penalize Z TRUE. default FALSE. remove_penalty_W penalize W TRUE. default FALSE. inference Whether inference without penalty post-selection inference adaptive lasso penalty. default TRUE. fix_lambda Without cross validation, fix lambda. default NULL. lambda_list Customize input lambda list validation. default NULL generate lambda list according glmnet. fix_ratio fixed ratio two-lambda strategy. ratio multiplied Z features. default NULL. NULL, select best ratio via cross validation holdout validation. gamma_adaptivelasso gamma adaptive lasso. Select c(1/2,1,2). default 1/2. use_sparseC Whether use approximate version weighting matrix C. approximation, use diagonal inverse C(inv_C) approximate inv_C. default TRUE. main study sample size limited, use_sparseC = TRUE recommended. main study sample size large enough, use_sparseC = FALSE recommended. seed.use seed  97.","code":""},{"path":"/reference/htlgmm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"htlgmm: — htlgmm","text":"beta: target coefficient estimation, features go order (,Z,W). lambda_list: lambda list cross validation. ratio_list: ratio list validation (cross validation holdout validation). fix_lambda: fix_lambda null, output fix_lambda. fix_ratio: fix_ratio null, output fix_ratio. selected_vars: inference post-selection inference, output inference results list. position: index nonzero positions, index comes X = (,Z,W). name: feature name nonzero positions. default name, name Ai, Zi, Wi. coef: coefficients nonzero positions. variance: variances features glm inference, selected features post-selection inference. pval: p values nonzero positions. FDR_adjust_position: FDR adjusted positions passing significant level 0.05 BH adjustment (Benjamini & Hochberg). FDR_adjust_name: feature name based FDR_adjust_position.","code":""},{"path":"/reference/htlgmm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"htlgmm: — htlgmm","text":"htlgmm: Heterogeneous Transfer Learning via generalized method moments(GMM).","code":""}]
